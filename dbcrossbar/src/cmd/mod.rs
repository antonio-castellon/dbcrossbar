//! Command parsing.

//use structopt::StructOpt;
use structopt_derive::StructOpt;

use crate::Result;

pub(crate) mod schema;

/// Command-line options, parsed using `structopt`.
#[derive(Debug, StructOpt)]
#[structopt(name = "dbcrossbar", about = "Convert between schema formats.")]
pub(crate) enum Opt {
    #[structopt(name = "schema")]
    #[structopt(after_help = r#"
INPUT FORMATS:
    json       A JSON schema previously output by dbcrossbar.
    pg         A PostgreSQL 'CREATE TABLE' statement.

OUTPUT FORMATS:
    json       Output the schema in dbcrossbar JSON format. This can be
               manipulated and reimported by dbcrossbar.
    pg:export  Generate a 'COPY (...) TO STDOUT WITH CSV HEADER' command which
               dumps the the specified output in a format than can be read by
               other databases. Arrays will be converted to JSON strings,
               geodata will be converted to GeoJSON, etc.
    pg:export:columns
               Similar to 'pg:export', but only output the column expressions
               which come after the 'SELECT'.
    bq:schema:temp
               Output a BigQuery JSON schema for a tempory loading table.
               Array columns will have the type STRING, etc., and will need to
               be processed using the SQL generated by 'bq:import', below.
    bq:schema  Output the final BigQuery 'JSON' schema, using proper column
               types like 'ARRAY<..>' instead of 'STRING'.
    bq:import  Output a SELECT which reads from the specified table,
               converts array columns from type 'STRING' to type 'ARRAY', and
               performs any other transformations required to finish the import.
"#)]
    Schema {
        #[structopt(flatten)]
        command: schema::Opt,
    },
}

pub(crate) fn run(opt: &Opt) -> Result<()> {
    match opt {
        Opt::Schema { command } => schema::run(command),
    }
}
