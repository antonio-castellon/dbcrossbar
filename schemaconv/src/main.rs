//! A CLI tool for converting between table schema formats.

#[macro_use]
extern crate common_failures;
extern crate env_logger;
#[macro_use]
extern crate failure;
#[macro_use]
extern crate log;
extern crate schemaconvlib;
extern crate serde;
extern crate serde_json;
#[macro_use]
extern crate structopt;
extern crate strum;
#[macro_use]
extern crate strum_macros;
extern crate url;

use common_failures::Result;
use failure::ResultExt;
use schemaconvlib::drivers::{
    bigquery::BigQueryDriver,
    postgres::PostgresDriver,
};
use std::io::{stdin, stdout, Write};
use structopt::StructOpt;
use url::Url;

#[derive(Clone, Copy, Debug, EnumString)]
enum OutputFormat {
    #[strum(serialize="json")]
    Json,
    #[strum(serialize="pg:export")]
    PostgresExport,
    #[strum(serialize="pg:export:columns")]
    PostgresExportColumns,
    #[strum(serialize="bq:schema:temp")]
    BigQuerySchemaTemp,
    #[strum(serialize="bq:schema")]
    BigQuerySchema,
    #[strum(serialize="bq:import")]
    BigQueryImport,
}

/// Our command-line arguments.
#[derive(Debug, StructOpt)]
#[structopt(name = "schemaconv", about = "Convert between schema formats.")]
#[structopt(after_help = r#"
OUTPUT FORMATS:
    json       Output the schema in schemaconv JSON format. This can be
               manipulated and reimported by schemaconv.
    pg:export  Generate a 'COPY (...) TO STDOUT WITH CSV HEADER' command which
               dumps the the specified output in a format than can be read by
               other databases. Arrays will be converted to JSON strings,
               geodata will be converted to GeoJSON, etc.
    pg:export:columns
               Similar to 'pg:export', but only output the column expressions
               which come after the 'SELECT'.
    bq:schema:temp
               Output a BigQuery JSON schema for a tempory loading table.
               Array columns will have the type STRING, etc., and will need to
               be processed using the SQL generated by 'bq:import', below.
    bq:schema  Output the final BigQuery 'JSON' schema, using proper column
               types like 'ARRAY<..>' instead of 'STRING'.
    bq:import  Output a SELECT which reads from the specified table,
               converts array columns from type 'STRING' to type 'ARRAY', and
               performs any other transformations required to finish the import.
"#)]
struct Opt {
    /// The URL of the database, followed by '#table_name' (as a URL fragment).
    /// If this URL is omitted, read a JSON table schema from stdin.
    url: Option<Url>,

    /// Rename the table.
    #[structopt(short = "t", long = "rename-table")]
    rename_table: Option<String>,

    /// The output format to use.
    #[structopt(short = "O", long = "output-format", default_value = "json")]
    output_format: OutputFormat,
}

quick_main!(run);

fn run() -> Result<()> {
    env_logger::init();
    let opt = Opt::from_args();
    debug!("{:?}", opt);

    // If we have a database URL, read our schema from the database.
    let mut table = if let Some(url) = &opt.url {
        let mut base_url = url.clone();
        base_url.set_fragment(None);
        let table_name = url.fragment().ok_or_else(|| {
            format_err!("Database URL must include table name after `#`")
        })?;
        PostgresDriver::fetch_from_url(&base_url, &table_name)?
    } else {
        let stdin = stdin();
        let mut input = stdin.lock();
        serde_json::from_reader(&mut input)
            .context("error reading from stdin")?
    };

    // Apply any requested transformations to our table schema.
    if let Some(rename_table) = &opt.rename_table {
        table.name = rename_table.to_owned();
    }

    // Output our table schema.
    let stdout = stdout();
    let mut out = stdout.lock();
    match opt.output_format {
        OutputFormat::Json => {
            serde_json::to_writer_pretty(&mut out, &table)?;
        }
        OutputFormat::PostgresExport => {
            PostgresDriver::write_select(&mut out, &table)?;
        }
        OutputFormat::PostgresExportColumns => {
            PostgresDriver::write_select_args(&mut out, &table)?;
        }
        OutputFormat::BigQuerySchemaTemp => {
            BigQueryDriver::write_json(&mut out, &table, true)?;
        }
        OutputFormat::BigQuerySchema => {
            BigQueryDriver::write_json(&mut out, &table, false)?;
        }
        OutputFormat::BigQueryImport => {
            BigQueryDriver::write_import_sql(&mut out, &table)?;
        }
    }
    write!(&mut out, "\n")?;

    Ok(())
}

